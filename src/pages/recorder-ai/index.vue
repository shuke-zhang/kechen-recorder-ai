<!-- eslint-disable ts/ban-ts-comment -->
<!-- eslint-disable import/no-duplicates -->
 <!-- #ifdef APP-PLUS -->
<script module="recorderCore" lang="renderjs">
// @ts-ignore
import Recorder from 'recorder-core'
import 'recorder-core/src/extensions/buffer_stream.player.js'

import RecordApp from 'recorder-core/src/app-support/app'
// import '../../../../uni_modules/Recorder-UniCore/app-uni-support.js'
import '../../../uni_modules/Recorder-UniCore/app-uni-support.js'
import 'recorder-core/src/engine/pcm'
import 'recorder-core/src/extensions/waveview'
// @ts-ignore

export default {
  data() {
    return {
    }
  },

  mounted() {
    // Appçš„renderjså¿…é¡»è°ƒç”¨çš„å‡½æ•°ï¼Œä¼ å…¥å½“å‰æ¨¡å—this
    RecordApp.UniRenderjsRegister(this)
  },
  methods: {
    // è¿™é‡Œå®šä¹‰çš„æ–¹æ³•ï¼Œåœ¨é€»è¾‘å±‚ä¸­å¯é€šè¿‡ RecordApp.UniWebViewVueCall(this,'this.xxxFunc()') ç›´æ¥è°ƒç”¨
    // è°ƒç”¨é€»è¾‘å±‚çš„æ–¹æ³•ï¼Œè¯·ç›´æ¥ç”¨ this.$ownerInstance.callMethod("xxxFunc",{args}) è°ƒç”¨ï¼ŒäºŒè¿›åˆ¶æ•°æ®éœ€è½¬æˆbase64æ¥ä¼ é€’
  },
}
</script>
<!-- #endif -->

<!-- eslint-disable import/first, import/order, import/no-named-default,import/no-duplicates -->
<script setup lang='ts'>
import type StreamPlayer from '@/components/StreamPlayer/StreamPlayer.vue'
import { NAV_BAR_HEIGHT, getStatusBarHeight } from '@/components/nav-bar/nav-bar'
import { default as RecorderInstance } from 'recorder-core'
import { default as RecordAppInstance } from 'recorder-core/src/app-support/app'
import { useTextFormatter } from './hooks/useTextFormatter'
import RecorderInputAuto from './recorder-input-auto.vue'
import useRecorder from './hooks/useRecorder'
import usePlayAudio from './hooks/usePlayAudio'
import useAiPage from './hooks/useAiPage'
import useAutoScroll from './hooks/useAutoScroll'
// import { useAiCall } from '@/store/modules/ai-call'
import { doubaoSpeechSynthesisFormat } from '@/api/audio'
import '../../../uni_modules/Recorder-UniCore/app-uni-support.js'
// import screensaver from './components/screensaver.vue'
/** éœ€è¦ç¼–è¯‘æˆå¾®ä¿¡å°ç¨‹åºæ—¶ï¼Œå¼•å…¥å¾®ä¿¡å°ç¨‹åºæ”¯æŒæ–‡ä»¶ */
// #ifdef MP-WEIXIN
import 'recorder-core/src/app-support/app-miniProgram-wx-support.js'
// #endif

import 'recorder-core/src/engine/pcm'
import 'recorder-core/src/extensions/waveview'
import type { StatusModel } from '@/components/audio-wave/audio-wave'
// import type { AiMessage } from '@/hooks'
import type { ChatHistoryModel } from '@/model/chat'
import type { UploadFileModel } from '@/model/chat'
import { addChatHistory, addChatHistory2 } from '@/api/chat-history'
import { request } from '@/utils/request'
// import usePlayAudio from './hooks/usePlayAudio'
const vueInstance = getCurrentInstance()?.proxy as any // å¿…é¡»å®šä¹‰åˆ°æœ€å¤–é¢ï¼ŒgetCurrentInstanceå¾—åˆ°çš„å°±æ˜¯å½“å‰å®ä¾‹this
const pageHeight = computed(() => {
  return `${getStatusBarHeight() + NAV_BAR_HEIGHT + 1}px`
})
/**
 * éŸ³é¢‘æ˜¯å¦æ­£åœ¨æ’­æ”¾
 */
const isStreamPlaying = ref(false)
const router = useRouter<{
  modelName: string
}>()

// const aiCall = useAiCall()
/** ä¸»è¦ç”¨äºåˆè¿›é¡µé¢çš„è¯­éŸ³æ’­æŠ¥ é»˜è®¤éœ€è¦ä¸¤ç§’åå˜ä¸ºtrue è§£å†³æ’­æ”¾å™¨éœ€è¦åˆå§‹åŒ–çš„2ç§’å·¦å³çš„bug */
const initialLoadPending = ref(false)
/**
 * ç”¨æ¥è¡¨è¿°å½“å‰çš„æ’­æ”¾çŠ¶æ€
 * - å½“è‡ªå·±æ²¡æœ‰å¼€å§‹è¯´è¯æ—¶ä½¿ç”¨ pending è¡¨ç¤ºå¯ä»¥ ä½ å¯ä»¥å¼€å§‹è¯´è¯
 * - å½“è‡ªå·±è¯´è¯ä¸­çš„æ—¶å€™ playing  è¡¨ç¤º æ­£åœ¨è¯†åˆ«...
 * - å½“aiåœ¨å›å¤å¹¶ä¸”è‡ªå·±å·²ç»è¯´è¯å®Œæˆçš„æ—¶å€™ stopped   è¡¨ç¤ºè¯´è¯æˆ–è€…ç‚¹å‡»æ‰“æ–­aiå›å¤
 */
const recorderStatus = ref<StatusModel >('pending')
/**
 * éŸ³é¢‘æ’­æ”¾ç»„ä»¶å®ä¾‹
 */
const streamPlayerRef = ref<InstanceType<typeof StreamPlayer>>()
/**
 * çŠ¶æ€æ é«˜åº¦
 */
const navbarHeight = computed(() => '45px')

const isAutoPlaying = ref(false)
const { handleMultiClick } = useMultiClickTrigger({
  onTrigger: () => {
    // router.push('/pages/test/index', { id: 123 })
    isAutoPlaying.value = !isAutoPlaying.value
    if (isAutoPlaying.value) {
      showToastSuccess('å¼€å¯è‡ªåŠ¨è¯†åˆ«').then(() => {
        handleRecorderTouchStart()
      })
    }
    else {
      showToastSuccess('å…³é—­è‡ªåŠ¨è¯†åˆ«').then(() => {
        isAutoRecognize.value = false
      })
    }
  },
})

const { base64ToArrayBuffer, playAudioInit, uploadFileAudio } = usePlayAudio(RecordAppInstance)

const {
  chatSSEClientRef,
  content,
  isAiMessageEnd,
  loading,
  modelName,
  modelSubTitle,
  modelPrefix,
  currentModel,
  replyForm,
  onSuccess,
  onFinish,
  resetAi,
  stopChat,
  onStart,
  onError,
  handleChangeAiModel,
  handleSendMsg,
  handleCopy,
  setAiContent,
} = useAiPage(pageHeight.value)
const startTime = ref(0)
const handleTouchStart = debounce(() => {
  removeEmptyMessagesByRole('assistant')
  startTime.value = Date.now()
  stopAll()

  console.log('ğŸŸ¢ è§¦å‘å‘é€æ¶ˆæ¯', content.value)
  handleConfirm()
  nextTick(() => {
    resetAndScrollToBottom()
  })
}, 300)
const {
  textRes,
  isFocus,
  isRunning,
  isFirstVisit,
  isAutoRecognize,
  showRecordingButton,
  isFirstRecorderText,
  recReq,
  handleRecorderTouchStart,
} = useRecorder({
  RecordApp: RecordAppInstance,
  Recorder: RecorderInstance,
  vueInstance,
  sendMessage: handleTouchStart,
  recorderAddText,
  userAudioUploadSuccess,
})

const {
  scrollTop,
  handleScroll,
  resetAndScrollToBottom,
  initHeights,
  scrollToBottom,
  scrolltolower,
} = useAutoScroll({
  contentList: content,
  vueInstance,
  scrollViewSelector: '.scroll-view',
  scrollContentSelector: '.scroll-content',
  immediate: true,
})

const { processText, textReset } = useTextFormatter()

const scrollViewRef = ref(null)
const animatedDots = ref('')
let dotTimer: NodeJS.Timeout | null = null
const currentIndex = ref<number | null>(null)
const isAudioPlaying = ref(false) // éŸ³é¢‘æ’­æ”¾çœŸæ­£çš„å¼€å§‹
const tempBuffers = ref<{ audio_data: string, text: string }[]>([])
const tempFormattedTexts = ref<string[]>([])
const streamData = ref<{
  text: string
  buffer: string
  id: number
}>()
// æ˜¯å¦åˆ‡æ¢åˆ°æ–°çš„æ¶ˆæ¯è¿›è¡Œæ’­æ”¾
const isSwitchingNewMessage = ref(false)
/** æ§åˆ¶å±ä¿ */
const isScreensaver = ref(true)
/** aiå›å¤çš„éŸ³é¢‘æ•°æ® */
const assistantAudioBuffers = ref<{
  buffers: ArrayBuffer
  id: number
}[]>([])
const isFirstText = ref(true)
const delayTimer: ReturnType<typeof setTimeout> | null = null
// å…¨å±€å˜é‡å­˜å‚¨æ ¼å¼åŒ–å™¨å®ä¾‹å’Œå½“å‰å¤„ç†çš„æ¶ˆæ¯ç´¢å¼•
let lastProcessedIndex: number | null = null
/** ä»£è¡¨å½“ç‚¹å‡»äº†éŸ³é¢‘å°å›¾æ ‡æ—¶ ï¼Œå¦‚æœæ­¤æ—¶aiæ¶ˆæ¯è¿˜æ²¡å›å¤å®ŒéŸ³é¢‘ä¹Ÿåœ¨æ’­æ”¾æ—¶ä¸ºtrue å¦åˆ™ä¸ºfalse ä¸»è¦æ˜¯ç”¨äºåˆ¤æ–­aiå›å¤ä¸­ç‚¹å‡»äº†éŸ³é¢‘å›¾æ ‡åä¸å†éœ€è¦è‡ªåŠ¨æ’­æ”¾ */
const hasUserInterruptedAutoPlay = ref(false)
const lastAiMsgEnd = ref(false)
/** æ— æ“ä½œé€»è¾‘ */
const idleTimeout = ref< ReturnType<typeof setTimeout> | null>(null)
const IDLE_DELAY = 10000 // 5ç§’
const canStartIdleTimer = computed(() => {
  return !isStreamPlaying.value && !loading.value
})
/**
 * ç”¨äºç¼“å­˜æ–°è¯†åˆ«åˆ°çš„å†…å®¹çš„å˜é‡
 */
const isCatchText = ref(true)
/**
 * ä¸´æ—¶å­˜å‚¨æ–°å¢å†å²è®°å½•çš„æ•°ç»„
 */
const addChatHistoryForm = ref<ChatHistoryModel>({})
/**
 * aiå›å¤çš„æœ€æ–°æ—¶é—´
 */
const assistantAudioTime = ref('')
/**
 * å…¨å±€è®¡æ•°å™¨ ä¸»è¦æ˜¯ç”¨äºåˆ¤æ–­aiè¿”å›çš„è¯·æ±‚éŸ³é¢‘çš„æ¥å£æ˜¯å¦å…¨éƒ¨è¯·æ±‚å®Œæˆ
 */
const ttsPendingCount = ref(0)
const hasPrepared = ref(false)
// æ¯æ¬¡å‘é€ TTSï¼ˆéŸ³é¢‘ï¼‰æ¥å£æ—¶ï¼Œ+1
function ttsRequestStart() {
  ttsPendingCount.value++
  if (ttsPendingCount.value < 0)
    ttsPendingCount.value = 0
}

// æ¯æ¬¡ TTS è¯·æ±‚ç»“æŸï¼ˆæ— è®ºæˆåŠŸå¤±è´¥ï¼‰ï¼Œ-1
function ttsRequestEnd() {
  if (ttsPendingCount.value > 0) {
    ttsPendingCount.value--
  }
  if (ttsPendingCount.value < 0)
    ttsPendingCount.value = 0
  checkIfAllReady()
}

// æ£€æŸ¥â€œå‡†å¤‡å®Œæˆâ€é€»è¾‘
function checkIfAllReady() {
  // AIå›å¤å·²ç»ç»“æŸï¼Œä¸”éŸ³é¢‘å…¨éƒ¨è¿”å›
  console.log(ttsPendingCount.value, isAiMessageEnd.value, 'ttsPendingCount.value')
  if (ttsPendingCount.value < 0)
    ttsPendingCount.value = 0
  if (isAiMessageEnd.value && ttsPendingCount.value === 0) {
    console.log('å‡†å¤‡å®Œæˆï¼ˆAIæµå¼å’Œæ‰€æœ‰éŸ³é¢‘æ¥å£å…¨éƒ¨å®Œæˆï¼‰', content.value)
    // ä¸Šä¼ å†å²è®°å½•åˆ°æœåŠ¡å™¨
    doPrepare()
  }
}

function doPrepare() {
  if (!content.value.length)
    return
  console.log(content.value, 'æŸ¥çœ‹å†…å®¹')

  const assistants = content.value.filter(item => item.role === 'assistant')
  const last = assistants[assistants.length - 1]
  console.log('æŸ¥çœ‹åˆ°assistants', last)

  if (!hasPrepared.value && last) {
    hasPrepared.value = true
    // è¿™é‡Œæ˜¯ä½ çš„â€œå‡†å¤‡å®Œæˆâ€æ“ä½œ
    console.log('aiéŸ³é¢‘å‡†å¤‡å®Œæˆå‡†å¤‡å®Œæˆï¼ˆåªæ‰§è¡Œä¸€æ¬¡ï¼‰')
    const _buffers = assistantAudioBuffers.value.sort((a, b) => a.id - b.id).map(item => item.buffers)
    const { wavBuffer } = playAudioInit(_buffers)
    let url = ''
    const content = last.content as string
    console.log('aiéŸ³é¢‘å¼€å§‹ä¸Šä¼ ')

    uploadFileAudio({
      wavBuffer,
      fileType: 'wav',
      fileNamePre: 'assistant-audio',
    }).then((res) => {
      console.log(res, 'aiéŸ³é¢‘æˆåŠŸå•¦')
      url = res.url
    }).finally(() => {
      addChatHistoryForm.value.assistantAudio = url || '' // éŸ³é¢‘åœ°å€
      addChatHistoryForm.value.assistantAudioTime = formatTime({ type: 'YYYY-MM-DD HH:mm:ss' }) // éŸ³é¢‘æ—¶é—´
      addChatHistoryForm.value.assistantOutput = content // æ–‡æœ¬ è¿™å„¿ç›´æ¥ç”¨last å› ä¸ºè¿™å„¿æ€»æ˜¯åœ¨ä¸‹æ¬¡å‘é€ä¹‹å‰æœ‰
      addChatHistoryForm.value.assistantOutputTime = assistantAudioTime.value // æ–‡æœ¬æ—¶é—´
      assistantAudioBuffers.value = []
      submitChatHistory()
    })
    // ...å…¶ä»–æ“ä½œ
  }
}
/**
 * æ–°å¢aièŠå¤©å†å²å¯¹è¯
 */
function submitChatHistory() {
  try {
    const data: ChatHistoryModel = {
      userAudio: addChatHistoryForm.value.userAudio,
      userAudioTime: addChatHistoryForm.value.userAudioTime,
      userInput: addChatHistoryForm.value.userInput,
      userInputTime: addChatHistoryForm.value.userInputTime,

      assistantAudio: addChatHistoryForm.value.assistantAudio,
      assistantAudioTime: addChatHistoryForm.value.assistantAudioTime,
      assistantOutput: addChatHistoryForm.value.assistantOutput,
      assistantOutputTime: addChatHistoryForm.value.assistantOutputTime,
    }
    console.log('æ–°å¢å†å²è®°å½•', data)

    addChatHistory(data).then((res) => {
      console.log('æ–°å¢å†å²è®°å½•æˆåŠŸâ€”â€”â€”â€”â€”â€”â€”â€”â€”â€”', res)
    }).finally(() => {
      addChatHistoryForm.value = {}
    })
  }
  catch (error) {
    console.log('æ–°å¢å¤±è´¥', error)
  }
  // return addChatHistory(data).then((res) => {
  //   console.log('æ–°å¢å†å²è®°å½•æˆåŠŸâ€”â€”â€”â€”â€”â€”â€”â€”â€”â€”', res)
  // }).catch((err) => {
  //   console.log('æ–°å¢å†å²è®°å½•å¤±è´¥â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”', err)
  // }).finally(() => {
  //   console.log('æ–°å¢å†å²è®°å½•finally')
  // })
}
function addChatHistory3(data: ChatHistoryModel) {
  console.log('è§¦å‘ addChatHistory3', data)
  request.post<ResponseList<ChatHistoryModel>>(
    {
      url: `/chatHistory/add/v1`,
      data,
      withToken: false,
    },
  )
}
/** é‡ç½®å®šæ—¶å™¨ */
function resetIdleTimer() {
  // è‹¥ä¸èƒ½å¯åŠ¨ idleTimerï¼ˆå› ä¸ºæ­£åœ¨æ’­æ”¾æˆ–AIæ­£åœ¨å›å¤ï¼‰ï¼Œå°±æ¸…é™¤å®šæ—¶å™¨å¹¶è¿”å›
  if (isScreensaver.value) {
    // console.log('å±ä¿ä¸­ï¼Œä¸é‡ç½®å®šæ—¶å™¨')

    return
  }
  console.log('ç›‘å¬åˆ°ç”¨æˆ·æ“ä½œï¼Œé‡ç½®å®šæ—¶å™¨')

  if (!canStartIdleTimer.value) {
    if (idleTimeout.value)
      clearTimeout(idleTimeout.value)
    return
  }

  // å¯åŠ¨ idle timer
  if (idleTimeout.value)
    clearTimeout(idleTimeout.value)

  idleTimeout.value = setTimeout(() => {
    stopAll()
    isScreensaver.value = true
    // æ¸…ç©ºæ‰€æœ‰å†…å®¹
    streamData.value = {
      text: '',
      buffer: '',
      id: 0,
    }
    content.value = []
    resetAi.value()
    replyForm.value = { content: '', role: 'user' }
  }, IDLE_DELAY)
}

/** ç‚¹å‡»è·³è½¬åˆ°å†å²é¡µé¢ */
function handleAiHistory() {
  router.push('/pages/ai-history/detail')
}

/** å‘é€æ¶ˆæ¯ç¡®è®¤æŒ‰é’® */
function onConfirm() {
  resetIdleTimer()
  handleConfirm()
}

/**
 * aiå†…å®¹è‡ªåŠ¨æ’­æ”¾éŸ³é¢‘
 */
async function autoPlayAiMessage(_text: string, index: number) {
  assistantAudioTime.value = formatTime({ type: 'YYYY-MM-DD HH:mm:ss' })
  console.log('autoPlayAiMessageè§¦å‘äº†')

  // è®¾ç½®å½“å‰æ’­æ”¾çš„æ¶ˆæ¯ç´¢å¼•
  currentIndex.value = index

  // å¦‚æœæ˜¯æ–°çš„æ¶ˆæ¯ï¼Œé‡ç½®æ ¼å¼åŒ–å™¨
  if (currentIndex.value !== lastProcessedIndex) {
    textReset()
    lastProcessedIndex = currentIndex.value
  }
  // å¼€å§‹è¯­éŸ³åˆæˆå¹¶æ’­æ”¾
  const longText = processText({
    text: _text,
    isFullText: false,
    forceFlush: isAiMessageEnd.value,
  })

  // å¤„ç†æ–‡æœ¬ ä¸‹é¢æ˜¯å¯¹æ¥åç«¯çš„éŸ³é¢‘ é‡‡ç”¨æ¥å£çš„æ–¹å¼
  if (longText.length > 0) {
    tempFormattedTexts.value.push(longText)
    //  åˆ¤æ–­æ˜¯ä¸æ˜¯æ–°çš„aiæ¶ˆæ¯
    if (tempFormattedTexts.value.findIndex(t => t === longText) === 0 && !isAiMessageEnd.value) {
      streamPlayerRef.value?.onStreamStop()
      assistantAudioBuffers.value = []
    }

    ttsRequestStart()
    doubaoSpeechSynthesisFormat({
      text: longText,
      id: tempFormattedTexts.value.findIndex(t => t === longText) || 0,
    }, tempFormattedTexts.value.findIndex(t => t === longText) === 0).then((res) => {
      const { audio_base64, text, id } = res
      streamData.value = {
        buffer: audio_base64,
        text,
        id,
      }
      const audio_buffer = base64ToArrayBuffer(audio_base64)
      assistantAudioBuffers.value.push({
        buffers: audio_buffer,
        id,
      })

      // aiè¿”å›çš„æ¶ˆæ¯ç»“æŸäº†
      if (isAiMessageEnd.value) {
        tempFormattedTexts.value = []
        hasUserInterruptedAutoPlay.value = false
      }
    }).catch((error) => {
      isStreamPlaying.value = false
      isAudioPlaying.value = false
      console.log(error, 'é”™è¯¯')
    }).finally(() => {
      ttsRequestEnd()
    })
  }
  isStreamPlaying.value = true
}

/**
 * å±ä¿è§¦å‘äº‹ä»¶
 */
// async function onScreensaverTrigger() {
//   isScreensaver.value = false
//   resetIdleTimer()
//   console.log('è¿›å…¥æ“ä½œé¡µé¢')

//   if (initialLoadPending.value) {
//     streamData.value = {
//       buffer: aiCall.callAudioData.audioData,
//       text: aiCall.callAudioData.text,
//       id: aiCall.callAudioData.id,
//     }
//     console.log('åˆå§‹åŒ–æ™šé¤æ’­æ”¾è§†é¢‘', streamData.value)
//   }
//   else {
//     // ç­‰å¾… initialLoadPending ä¸º true å†ç»§ç»­
//     try {
//       await waitUntil(() => initialLoadPending.value)
//       streamData.value = {
//         buffer: aiCall.callAudioData.audioData,
//         text: aiCall.callAudioData.text,
//         id: aiCall.callAudioData.id,
//       }
//       console.log('ç­‰å¾…åˆå§‹åŒ–å®Œæˆå•¦')
//     }
//     catch (e) {
//       console.error('ç­‰å¾… initialLoadPending è¶…æ—¶', e)
//     }
//   }

//   handleTouchStart()
// }

// function waitUntil(conditionFn: () => boolean, interval = 50, timeout = 5000): Promise<void> {
//   return new Promise((resolve, reject) => {
//     const start = Date.now()
//     const timer = setInterval(() => {
//       if (conditionFn()) {
//         clearInterval(timer)
//         resolve()
//       }
//       else if (Date.now() - start > timeout) {
//         clearInterval(timer)
//         reject(new Error('waitUntil è¶…æ—¶'))
//       }
//     }, interval)
//   })
// }

function userMsgFormat(prefix: string, text: string, isFormat = true) {
  if (!isFormat)
    return text
  const index = text.indexOf(prefix)

  if (index === -1) {
    return text // æ²¡æœ‰å‰ç¼€å°±è¿”å›åŸå†…å®¹
  }
  return text.slice(index + prefix.length)
}

/**
 * å‘é€æ¶ˆæ¯ç¡®è®¤æŒ‰é’®
 */
async function handleConfirm() {
  streamPlayerRef.value?.onStreamStop()
  tempFormattedTexts.value = []
  tempBuffers.value = []
  removeEmptyMessagesByRole('assistant') // ç§»é™¤assistantè§’è‰²çš„ç©ºæ¶ˆæ¯

  //  ç‚¹å‡»æ—¶å¦‚æœaiæ¶ˆæ¯æ²¡æœ‰è¿”å›å®Œ ï¼Œå¹¶ä¸”æ­£åœ¨æ’­æ”¾ï¼Œç›´æ¥åœæ­¢
  if ((!isAiMessageEnd.value && loading.value) || isStreamPlaying.value) {
    await stopAll()
    // åœæ­¢éŸ³é¢‘æ’­æ”¾
    handleSendMsg()
    return
  }

  handleSendMsg()
}

/**
 * aiæ¶ˆæ¯ç‚¹å‡»è¯­éŸ³
 * @warning ç”±äºè¯­éŸ³ç‚¹å‡»ä¹‹åæ’­æ”¾éŸ³é¢‘ä¼šæœ‰å»¶è¿Ÿï¼Œ æ‰€ä»¥åœ¨è¿™å„¿ç›´æ¥è®¾ç½®çŠ¶æ€
 */
const handleRecorder = debounce((text: string, index: number) => {
  // å¦‚æœ AI æ¶ˆæ¯è¿˜åœ¨å›å¤ä¸­ï¼Œæ ‡è®°ç”¨æˆ·ä¸­æ–­è‡ªåŠ¨æ’­æ”¾
  if (!isAiMessageEnd.value) {
    hasUserInterruptedAutoPlay.value = true
  }
  // å½“å‰å·²ç»åœ¨æ’­æ”¾æ­¤æ¡æ¶ˆæ¯
  if (currentIndex.value === index && isStreamPlaying.value) {
    console.log('ğŸŸ¡ å†æ¬¡ç‚¹å‡»åŒä¸€æ¡ï¼Œæ‰§è¡Œåœæ­¢')
    streamPlayerRef.value?.onStreamStop()
    currentIndex.value = null
    isStreamPlaying.value = false
    return
  }

  // å¦‚æœæ­£åœ¨æ’­æ”¾ä¸”æ˜¯æ–°çš„æ¶ˆæ¯ï¼Œå…ˆåœæ­¢å½“å‰æ’­æ”¾
  if (currentIndex.value !== null && isStreamPlaying.value) {
    isSwitchingNewMessage.value = true
    console.log('ğŸ”´ åˆ‡æ¢æ–°æ¶ˆæ¯ï¼Œå…ˆåœæ­¢å·²æ’­æ”¾çš„æ¶ˆæ¯')
    streamPlayerRef.value?.onStreamStop()
    isStreamPlaying.value = false
  }

  // âœ… å¼€å§‹æ–°çš„æ’­æ”¾
  console.log('ğŸŸ¢ å¼€å§‹æ’­æ”¾æ–°æ¶ˆæ¯')
  isStreamPlaying.value = true
  currentIndex.value = index

  const longTexts = processText({
    text,
    isFullText: true,
  })

  longTexts.forEach((longText, i) => {
    if (longText.trim().length > 0) {
      doubaoSpeechSynthesisFormat({
        text: longText,
        id: i,
      }).then((res) => {
        const { audio_base64, text, id } = res
        streamData.value = {
          buffer: audio_base64,
          text,
          id,
        }
      }).catch((e) => {
        console.log('ç‚¹å‡»æ—¶æ•è·åˆ°é”™è¯¯', e)
        isStreamPlaying.value = false
        currentIndex.value = null
      })
    }
  })
}, 500)

/**
 * è¯­éŸ³æ’­æ”¾çœŸæ­£çš„å¼€å§‹
 */
function onStreamPlayStart() {
  isAudioPlaying.value = true
  // é˜²æ­¢ç”±äºæ’­æ”¾å™¨åœæ­¢æ—¶è§¦å‘å»¶è¿Ÿï¼Œæ‰€ä»¥è¿™å„¿ä¹Ÿè¦è®¾ç½®çŠ¶æ€
  isStreamPlaying.value = true
  recorderStatus.value = 'stopped'
}

/**
 * è¯­éŸ³æ’­æ”¾ç»“æŸ
 */
function onStreamPlayEnd() {
  /**
   * è¿™å„¿ä½¿ç”¨  isSwitchingNewMessage æ¥æ§åˆ¶ç«‹å³æ›´æ–° isStreamPlaying çš„çŠ¶æ€çš„
   * å·²çŸ¥å½“æˆ‘å‰å‡ åˆ‡æ¢æ–°çš„æ¶ˆæ¯æ’­æ”¾æ—¶ ï¼Œ ä¼šè§¦å‘è¯¥å‡½æ•°ï¼Œæ­¤æ—¶ä¼šå…³é—­ isStreamPlaying çš„çŠ¶æ€
   * æ­¤æ—¶ isSwitchingNewMessage çš„çŠ¶æ€å°±ä¸æ˜¯åœ¨æˆ‘ç‚¹å‡»åç«‹å³è§¦å‘äº†ï¼Œè€Œæ˜¯åœ¨éŸ³é¢‘æ’­æ”¾æ—¶æ‰è§¦å‘ï¼Œè¿™ä¼šé€ æˆè§‚çœ‹ä¸Šçš„å»¶è¿Ÿ
   * æ‰€ä»¥åœ¨è¿™å„¿ä½¿ç”¨ isSwitchingNewMessage æ¥æ§åˆ¶ç«‹å³æ›´æ–° isStreamPlaying çš„çŠ¶æ€çš„
   */
  if (isSwitchingNewMessage.value) {
    isSwitchingNewMessage.value = false
  }
  else {
    isStreamPlaying.value = false
    currentIndex.value = null
  }
  isAudioPlaying.value = false
  recorderStatus.value = 'pending'
}
/**
 * è¯­éŸ³æ’­æ”¾åœæ­¢
 */
function onStreamStop() {
  isStreamPlaying.value = false
  isAudioPlaying.value = false
  currentIndex.value = null
}

/**
 * æ ¹æ®è§’è‰²ç±»å‹åˆ é™¤æœ€åä¸€æ¡æ¶ˆæ¯
 */
function removeEmptyMessagesByRole(type: string) {
  for (let i = content.value.length - 1; i >= 0; i--) {
    const item = content.value[i]
    const raw = item.content
    const text = Array.isArray(raw) ? raw[0]?.text ?? '' : raw ?? ''

    const isEmpty = typeof text === 'string' && text.trim() === ''
    if (item.role === type && isEmpty) {
      content.value.splice(i, 1)
    }
  }
}
let incrementTimer: ReturnType<typeof setTimeout> | null = null
const incrementCacheText = ref('')
const hasInsertedPlaceholder = ref(false)
const lastInsertResult = ref<{ id: number } | null>(null)

function recorderAddText(text: string): { id: number } {
  if (!text) {
    return { id: -1 }
  }
  ttsPendingCount.value = 0

  recorderStatus.value = 'playing'

  if (!hasInsertedPlaceholder.value) {
    hasInsertedPlaceholder.value = true
    // è°ƒç”¨addTextå¹¶ç¼“å­˜æ•´ä¸ªè¿”å›å€¼
    lastInsertResult.value = addText(text)
    return toRaw(lastInsertResult.value || { id: -2 })
  }
  // å¢é‡æœŸé—´åªåšå†…å®¹ç¼“å­˜
  incrementCacheText.value = text
  if (incrementTimer)
    clearTimeout(incrementTimer)
  incrementTimer = setTimeout(() => {
    incrementTimer = null
    incrementCacheText.value = ''
  }, 1500)
  // åé¢æ¯æ¬¡éƒ½ç›´æ¥è¿”å›ç¬¬ä¸€æ¬¡addTextçš„è¿”å›å†…å®¹
  return toRaw(lastInsertResult.value || { id: -3 })
}

/** é‡ç½®ç¼“å­˜çŠ¶æ€ */
function resetRecorderTextState() {
  incrementCacheText.value = ''
  hasInsertedPlaceholder.value = false
  lastInsertResult.value = null
}

function addText(text: string) {
  const last = content.value[content.value.length - 1]

  if (last?.isRecordingPlaceholder)
    return last.id === 0 ? { id: last.id } : { id: last.id || -2 }
  stopAll()
  console.log('å…³é—­é€»è¾‘è°ƒç”¨æœ€åç»“æŸ')

  replyForm.value.content = modelPrefix.value + text
  let finalText = text
  if (!text.startsWith(modelPrefix.value)) {
    finalText = modelPrefix.value + text
  }
  const sendText = setAiContent({
    type: 'send',
    msg: replyForm.value.content, // ç©ºæ¶ˆæ¯ä½œä¸ºå ä½
    modeName: modelName.value || '',
    id: content.value.length,
  })
  sendText.isRecordingPlaceholder = true // âœ… æ ‡è®°å ä½æ¶ˆæ¯
  content.value?.push(sendText)
  recorderStatus.value = 'playing'
  console.warn('è§¦å‘æ–°å¢æ¶ˆæ¯', recorderStatus.value)
  return {
    id: sendText.id!,
  }
}

/**
 * ç”¨æˆ·è¯­éŸ³ä¸Šä¼ æˆåŠŸçš„å›è°ƒå‡½æ•°
 */
function userAudioUploadSuccess(res: UploadFileModel & { id: number, userInputTime: string }) {
  //  é€šè¿‡idæ¥æŸ¥è¯¢content.valueä¸­ç›¸åŒ¹é…çš„æ•°æ®ï¼Œå¹¶ä¸”èµ‹å€¼
  // å…ˆé‡ç½®åˆšåˆšç¼“å­˜çš„çŠ¶æ€
  resetRecorderTextState()
  const item = content.value.find(item => item.id === res.id && item.role === 'user')
  if (item) {
    item.userAudioUrl = res.url
    item.userAudioTime = formatTime({ type: 'YYYY-MM-DD HH:mm:ss' })
    item.userInputTime = res.userInputTime
  }

  addChatHistoryForm.value.userAudio = res.url // éŸ³é¢‘åœ°å€
  addChatHistoryForm.value.userAudioTime = formatTime({ type: 'YYYY-MM-DD HH:mm:ss' }) // éŸ³é¢‘ä¸Šä¼ æ—¶é—´
  addChatHistoryForm.value.userInput = userMsgFormat(modelPrefix.value, (item?.content as string) || '', true)// æ–‡æœ¬
  addChatHistoryForm.value.userInputTime = res.userInputTime // æ–‡æœ¬æ—¶é—´
  console.log('è¯­éŸ³è¯†åˆ«ç»“æŸäº†', addChatHistoryForm.value)
}

async function stopAll() {
  console.log('ğŸš« å¼ºåˆ¶å…³é—­æ‰€æœ‰é€»è¾‘')
  // åœæ­¢aiå›å¤çš„æ¶ˆæ¯
  await stopChat.value()
  // åœæ­¢éŸ³é¢‘æ’­æ”¾ å®é™…ä¸Šè¿™å„¿å¹¶ä¸æ˜¯åŒæ­¥çš„ï¼Œåªæ˜¯è§¦å‘äº†stopæ–¹æ³•
  await streamPlayerRef.value?.onStreamStop()
  currentIndex.value = null
  // é‡ç½®æ ¼å¼åŒ–å™¨
  textReset()
  // é‡ç½®æ’­æ”¾çŠ¶æ€
  isStreamPlaying.value = false
  // é‡ç½®éŸ³é¢‘æ’­æ”¾çœŸæ­£çš„çŠ¶æ€
  isAudioPlaying.value = false
  hasPrepared.value = false
  ttsPendingCount.value = 0
  addChatHistoryForm.value = {}

  console.log('å…³é—­é€»è¾‘å‡½æ•°ç»“æŸ-----')
}

watch([isStreamPlaying, loading], ([isPlaying, isLoading]) => {
  if (!isPlaying || !isLoading) {
    // éƒ½ç»“æŸäº†æ‰å¼€å§‹å€’è®¡æ—¶
    resetIdleTimer()
  }
  else {
    // ä»»æ„ä¸€ä¸ªæ˜¯trueï¼Œå°±æ¸…æ‰å·²æœ‰å®šæ—¶å™¨
    if (idleTimeout.value)
      clearTimeout(idleTimeout.value)
  }
})
// æ·»åŠ ä¸€ä¸ªç›‘å¬æœ€åä¸€æ¡æ¶ˆæ¯å†…å®¹çš„å˜åŒ–ï¼ˆå¯¹äºæµå¼è¾“å‡ºéå¸¸æœ‰ç”¨ï¼‰
watch(
  () => content.value[content.value.length - 1]?.content,
  () => {
    if (content.value.length > 0) {
      nextTick(() => {
        scrollToBottom()
      })

      // æ£€æŸ¥æœ€åä¸€æ¡æ¶ˆæ¯æ˜¯å¦æ˜¯AIçš„å›å¤
      const lastMessage = content.value[content.value.length - 1]
      if (lastMessage?.role === 'assistant' && lastMessage?.streaming) {
        recorderStatus.value = 'stopped'
        // è‡ªåŠ¨æ’­æ”¾
        autoPlayAiMessage(lastMessage.content as string || ' ', content.value.length - 1)
      }
    }
  },
)

watch(() => isAiMessageEnd.value, (newVal) => {
  if (newVal) {
    lastAiMsgEnd.value = true

    tempFormattedTexts.value = []
    hasUserInterruptedAutoPlay.value = false
    checkIfAllReady()
  }
})

// watch(ttsPendingCount, () => {
//   checkIfAllReady()
// })

watch(
  content.value,
  (newVal) => {
    console.log('contentå˜åŒ–äº†', newVal)

    nextTick(() => {
      scrollToBottom()
    })
  },
  { deep: true },
)

// ç›‘å¬è¯­éŸ³è¯†åˆ«å¼€å§‹å’Œç»“æŸ æ·»åŠ çœç•¥å·åŠ¨ç”»
watch(() => isRunning.value, (val: boolean) => {
  if (val) {
    animatedDots.value = '.'
    dotTimer = setInterval(() => {
      animatedDots.value = animatedDots.value.length >= 3 ? '.' : `${animatedDots.value}.`
    }, 500)
  }
  else {
    if (dotTimer)
      clearInterval(dotTimer)
    dotTimer = null
    animatedDots.value = ''
  }
})

/** è¯­éŸ³è¯†åˆ«ç»“æœè¿”å› - å¯ä»¥æ·»åŠ è¯†åˆ«  */
watch(() => textRes.value, async (newVal) => {
  await nextTick() // ç¡®ä¿è§†å›¾æ›´æ–°å®Œæˆ
  // replyForm.value.content = modelPrefix.value + newVal as string
  replyForm.value.content = newVal?.startsWith(modelPrefix.value) ? newVal : modelPrefix.value + newVal
})

watch(() => replyForm.value.content, (newVal) => {
  resetIdleTimer()
})

onMounted(() => {
  (vueInstance as any).isMounted = true
  RecordAppInstance.UniPageOnShow(vueInstance)
  recReq().then((res) => {
    isFirstVisit.value = false
    setTimeout(() => {
      initialLoadPending.value = true
      // ç›´æ¥å¼€å§‹å½•éŸ³ - æ¨¡æ‹Ÿå½•éŸ³æŒ‰é’®æŒ‰ä¸‹æ“ä½œ
      if (isAutoPlaying.value) {
        handleRecorderTouchStart()
      }
    }, 1500)
  }).catch((err) => {
    showToastError(err)
    console.log(err, 'è¯·æ±‚æƒé™æ‹’ç»')
  })

  initHeights()
})

onShow(() => {
  if ((vueInstance as any)?.isMounted) {
    RecordAppInstance.UniPageOnShow(vueInstance)
  }
})

router.ready(() => {
  handleChangeAiModel()
})
</script>

<template>
  <view @touchstart="resetIdleTimer" @touchmove="resetIdleTimer" @touchend="resetIdleTimer" @click="resetIdleTimer" @scroll="resetIdleTimer">
    <nav-bar :show-back="false" transparent>
      <!-- <template #left>
        <view>
          <icon-font :name="isAutoPlayAiMessage ? 'sound' : 'mute'" :color="isAutoPlayAiMessage ? COLOR_PRIMARY : ''" size="40" class="ml-20rpx" @click="handleAutoPlayAiMessage" />
        </view>
      </template> -->

      <template #right>
        <!-- <view class="flex  pr-50rpx">
          <icon-font name="setting" color="#000" size="40" @click="handleToSetting" />
        </view> -->
        <view @click="handleAiHistory">
          <icon-font name="history" color="#000" size="40" />
        </view>
      </template>

      <text class="opacity-0" @click="handleMultiClick">
        æŸ¯ä»”AI
      </text>
    </nav-bar>

    <!-- æµå¼æµå¼aiæ¶ˆæ¯ -->
    <GaoChatSSEClient
      ref="chatSSEClientRef"
      @on-open="onStart"
      @on-error="onError"
      @on-message="onSuccess && onSuccess?.($event)"
      @on-finish="onFinish"
    />

    <!-- éŸ³é¢‘æ’­æ”¾ç»„ä»¶ -->
    <!-- #ifdef APP-PLUS -->
    <StreamPlayer
      ref="streamPlayerRef"
      :stream-data="streamData"
      @on-stream-play-start="onStreamPlayStart"
      @on-stream-play-end="onStreamPlayEnd"
      @on-stream-stop="onStreamStop"
    />
    <!-- #endif -->

    <!-- <view v-show="!isScreensaver"> -->
    <view v-show="true">
      <view :style="{ height: `calc(100vh - 200rpx - ${navbarHeight})` }">
        <view
          class="w-full h-70%  pointer-events-none"
        >
          <image
            :src="(isStreamPlaying && isAudioPlaying) ? '/static/images/aiPageBg.gif' : '/static/images/aiPageBg-quiet.png'"
            mode="aspectFit"
            class="size-100%"
          />
        </view>
        <view class="h-30% pb-120rpx">
          <scroll-view
            ref="scrollViewRef"
            scroll-y
            :scroll-top="scrollTop"
            class=" scroll-view pr-20rpx pl-20rpx  h-full"
            :scroll-with-animation="true"
            @scroll="handleScroll"
            @scrolltolower="scrolltolower"
          >
            <view class="scroll-content">
              <!--  content.length === 0 -->
              <view v-if="false" class="h-full flex justify-end flex-col items-center ">
                <view>
                  <image
                    class="ai-img"
                    :src="`/static/images/ai-logo/${currentModel?.icon}.png`"
                    mode="aspectFill"
                  />
                </view>
                <view class="font-size-60rpx mt-20rpx">
                  æˆ‘æ˜¯{{ modelSubTitle }}
                </view>
                <view class="mt-20rpx w-80%">
                  æˆ‘å¯ä»¥å¸®ä½ æœç´¢ã€ç­”ç–‘ã€å†™ä½œã€è¯·åœ¨ä¸‹æ–¹è¾“å…¥ä½ çš„å†…å®¹~
                </view>
              </view>

              <view v-for="(msg, index) in content" :key="index" class="py-16rpx">
                <!-- ç”¨æˆ·æ¶ˆæ¯ -->
                <view v-if="msg.role === 'user'" class=" flex  flex-justify-end opacity-60">
                  <view class="message-bubble p-32rpx border-rd-16rpx   bg-#07c160 color-white max-w-80%">
                    <text selectable>
                      <!-- é¦–å…ˆåˆ¤æ–­ ç”¨æˆ·æ¶ˆæ¯ä¸´æ—¶åŠ è½½çŠ¶æ€ å¦‚æœæ˜¯åˆ™ä»£è¡¨æ˜¯è¯­éŸ³è¯†åˆ«æ¶ˆæ¯ å¦åˆ™å±•ç¤ºå·²ç»æ·»åŠ è¿›å»çš„æ¶ˆæ¯ -->
                      {{
                        msg.isRecordingPlaceholder
                          ? (textRes || '') + (isRunning && textRes ? animatedDots : '')
                          : Array.isArray(msg.content)
                            ? userMsgFormat(modelPrefix, (msg.content as any)[0].text, true)
                            : userMsgFormat(modelPrefix, msg.content || '', true)
                      }}
                    </text>
                    <!-- æµå¼åŠ è½½åŠ¨ç”» -->
                    <view v-if="msg.isRecordingPlaceholder && !textRes" class="flex-center">
                      <uni-load-more icon-type="auto" status="loading" :show-text="false" />
                    </view>
                  </view>
                </view>

                <!-- AIæ¶ˆæ¯ï¼ˆå«åŠ è½½çŠ¶æ€ï¼‰ -->
                <view v-if="msg.role === 'assistant'" class="flex justify-start opacity-60">
                  <Icon-font name="zhipu" class="mt-20rpx mr-10rpx" />
                  <view class="flex mt-16rpx mb-16rpx flex-justify-start bg-#ffffff color-#333333 max-w-80% border-rd-16rpx">
                    <view
                      class="message-bubble  p-32rpx border-rd-16rpx w-100%"
                      :class="[msg.streaming && !(msg.content && msg.content!.length) ? 'flex-center w-120rpx h-120rpx ' : '']"
                    >
                      <view v-if="msg.content">
                        <UaMarkdown :source="`${msg.content}`" :show-line="false" />

                        <view class="h-2rpx  bg-black-3 my-10rpx" />

                        <view class="flex items-center justify-end ">
                          <view class="border-rd-16rpx size-60rpx bg-#e8ecf5 flex-center" @click="handleCopy(msg.content as string)">
                            <icon-font name="copy" :color="COLOR_PRIMARY" :size="28" />
                          </view>
                          <view class="border-rd-16rpx size-60rpx  bg-#e8ecf5 flex-center  ml-20rpx" @click="handleRecorder(msg.content as string, index)">
                            <audio-wave v-if="isStreamPlaying && currentIndex === index" status="playing" :color="COLOR_PRIMARY" />
                            <icon-font v-else name="sound" :color="COLOR_PRIMARY" :size="28" />
                          </view>
                        </view>
                      </view>
                      <!-- æµå¼åŠ è½½åŠ¨ç”» -->
                      <view v-if=" msg.streaming && !(msg.content && msg.content!.length)" class="flex-center">
                        <uni-load-more icon-type="auto" status="loading" :show-text="false" />
                      </view>
                    </view>
                  </view>
                </view>
              </view>
            </view>
          </scroll-view>
        </view>
      </view>

      <!-- ç»Ÿä¸€è¾“å…¥æ¡† -->
      <RecorderInputAuto
        v-model:model-value="replyForm.content"
        v-model:focus="isFocus"
        v-model:show-recording-button="showRecordingButton"
        v-model:status="recorderStatus"
        placeholder="è¯·è¾“å…¥æ‚¨çš„é—®é¢˜..."
        btn-text="å‘é€"
        @confirm="onConfirm"
        @click-stopped="stopAll, recorderStatus = 'pending'"
      />
    </view>

    <!-- å±ä¿ -->
    <!-- <screensaver v-model:show="isScreensaver" @on-trigger="onScreensaverTrigger" /> -->
  </view>
</template>

<style lang="scss">
.message-bubble {
  box-shadow: 0 2px 4px rgba(0, 0, 0, 0.1);
}
.ai-img {
  width: 160rpx;
  height: 160rpx;
}
</style>

<route lang="json" pages="page">
  {
       "style": { "navigationBarTitleText": "å½•éŸ³","navigationStyle": "custom" }
  }
</route>
