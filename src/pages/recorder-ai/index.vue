<!-- eslint-disable ts/ban-ts-comment -->
<!-- eslint-disable import/no-duplicates -->
 <!-- #ifdef APP-PLUS -->
<script module="recorderCore" lang="renderjs">
// @ts-ignore
import Recorder from 'recorder-core'
import 'recorder-core/src/extensions/buffer_stream.player.js'

import RecordApp from 'recorder-core/src/app-support/app'
// import '../../../../uni_modules/Recorder-UniCore/app-uni-support.js'
import '../../../uni_modules/Recorder-UniCore/app-uni-support.js'
import 'recorder-core/src/engine/pcm'
import 'recorder-core/src/extensions/waveview'
// @ts-ignore

export default {
  data() {
    return {
    }
  },

  mounted() {
    // Appçš„renderjså¿…é¡»è°ƒç”¨çš„å‡½æ•°ï¼Œä¼ å…¥å½“å‰æ¨¡å—this
    RecordApp.UniRenderjsRegister(this)
  },
  methods: {
    // è¿™é‡Œå®šä¹‰çš„æ–¹æ³•ï¼Œåœ¨é€»è¾‘å±‚ä¸­å¯é€šè¿‡ RecordApp.UniWebViewVueCall(this,'this.xxxFunc()') ç›´æ¥è°ƒç”¨
    // è°ƒç”¨é€»è¾‘å±‚çš„æ–¹æ³•ï¼Œè¯·ç›´æ¥ç”¨ this.$ownerInstance.callMethod("xxxFunc",{args}) è°ƒç”¨ï¼ŒäºŒè¿›åˆ¶æ•°æ®éœ€è½¬æˆbase64æ¥ä¼ é€’
  },
}
</script>
<!-- #endif -->

<!-- eslint-disable import/first, import/order, import/no-named-default,import/no-duplicates -->
<script setup lang='ts'>
import type StreamPlayer from '@/components/StreamPlayer/StreamPlayer.vue'
import { NAV_BAR_HEIGHT, getStatusBarHeight } from '@/components/nav-bar/nav-bar'
import { default as RecorderInstance } from 'recorder-core'
import { default as RecordAppInstance } from 'recorder-core/src/app-support/app'
import { useTextFormatter } from './hooks/useTextFormatter'
import RecorderInput from './recorder-input.vue'
import useRecorder from './hooks/useRecorder'
import useAiPage from './hooks/useAiPage'
import useAutoScroll from './hooks/useAutoScroll'
import { useMultiClickTrigger } from '@/hooks'
import { doubaoSpeechSynthesisFormat } from '@/api/audio'
import '../../../uni_modules/Recorder-UniCore/app-uni-support.js'
/** éœ€è¦ç¼–è¯‘æˆå¾®ä¿¡å°ç¨‹åºæ—¶ï¼Œå¼•å…¥å¾®ä¿¡å°ç¨‹åºæ”¯æŒæ–‡ä»¶ */
// #ifdef MP-WEIXIN
import 'recorder-core/src/app-support/app-miniProgram-wx-support.js'
// #endif

// #ifdef H5 || MP-WEIXIN
import 'recorder-core/src/engine/pcm'
import 'recorder-core/src/extensions/waveview'
// #endif
const vueInstance = getCurrentInstance()?.proxy as any // å¿…é¡»å®šä¹‰åˆ°æœ€å¤–é¢ï¼ŒgetCurrentInstanceå¾—åˆ°çš„å°±æ˜¯å½“å‰å®ä¾‹this
const pageHeight = computed(() => {
  return `${getStatusBarHeight() + NAV_BAR_HEIGHT + 1}px`
})
/**
 * éŸ³é¢‘æ˜¯å¦æ­£åœ¨æ’­æ”¾
 */
const isStreamPlaying = ref(false)
const router = useRouter<{
  modelName: string
}>()
console.log(router.query, 'æ£€æŸ¥è·¯ç”±å‚æ•°')

/**
 * éŸ³é¢‘æ’­æ”¾ç»„ä»¶å®ä¾‹
 */
const streamPlayerRef = ref<InstanceType<typeof StreamPlayer>>()
const { handleMultiClick } = useMultiClickTrigger({
  onTrigger: () => {
    router.push('/pages/test/index', { id: 123 })
  },
})

const {
  chatSSEClientRef,
  loading,
  content,
  isAiMessageEnd,
  modelName,
  currentModel,
  replyForm,
  aiPageContent,
  aiScrollView,
  stopChat,
  onStart,
  onError,
  onSuccess,
  onFinish,
  handleChangeAiModel,
  handleSendMsg,
  handleCopy,
  setAiContent,
} = useAiPage(pageHeight.value)

const {
  textRes,
  isFocus,
  iseRecorderTouchStart,
  isRecorderClose,
  isRunning,
  isFirstVisit,
  showRecordingButton,
  recReq,
  handleRecorderClose,
  handleShowRecorder,
  handleRecorderTouchStart,
  handleRecorderTouchEnd,
  handleRecorderConfirm,
} = useRecorder({
  RecordApp: RecordAppInstance,
  Recorder: RecorderInstance,
  vueInstance,
})

const {
  scrollTop,
  handleScroll,
  resetAndScrollToBottom,
  initHeights,
  scrollToBottom,
  scrolltolower,
} = useAutoScroll({
  contentList: content,
  vueInstance,
  scrollViewSelector: '.scroll-view',
  scrollContentSelector: '.scroll-content',
  immediate: true,
})

const { processText, textReset } = useTextFormatter()

const scrollViewRef = ref(null)
const animatedDots = ref('')
let dotTimer: NodeJS.Timeout | null = null
const currentIndex = ref<number | null>(null)
const isAudioPlaying = ref(false)
const tempBuffers = ref<{ audio_data: string, text: string }[]>([])
const tempFormattedTexts = ref<string[]>([])
const streamData = ref<{
  text: string
  buffer: string
  id: number
}>()
/**
 * æ˜¯å¦è‡ªåŠ¨æ’­æ”¾
 */
const isAutoPlayAiMessage = ref(true)
// å…¨å±€å˜é‡å­˜å‚¨æ ¼å¼åŒ–å™¨å®ä¾‹å’Œå½“å‰å¤„ç†çš„æ¶ˆæ¯ç´¢å¼•
let lastProcessedIndex: number | null = null

/**
 * aiå†…å®¹è‡ªåŠ¨æ’­æ”¾éŸ³é¢‘
 */
async function autoPlayAiMessage(text: string, index: number) {
  if (!isAutoPlayAiMessage.value)
    return
  if (!text || text.trim() === '')
    return
  if (!isApp)
    return
  // è®¾ç½®å½“å‰æ’­æ”¾çš„æ¶ˆæ¯ç´¢å¼•
  currentIndex.value = index

  // å¦‚æœæ˜¯æ–°çš„æ¶ˆæ¯ï¼Œé‡ç½®æ ¼å¼åŒ–å™¨
  if (currentIndex.value !== lastProcessedIndex) {
    textReset()
    lastProcessedIndex = currentIndex.value
  }
  // å¼€å§‹è¯­éŸ³åˆæˆå¹¶æ’­æ”¾
  const longText = processText(text)

  // å¤„ç†æ–‡æœ¬ ä¸‹é¢æ˜¯å¯¹æ¥åç«¯çš„éŸ³é¢‘ é‡‡ç”¨æ¥å£çš„æ–¹å¼
  if (longText.length > 0) {
    tempFormattedTexts.value.push(longText)

    doubaoSpeechSynthesisFormat({
      text: longText,
      id: tempFormattedTexts.value.findIndex(t => t === longText) || 0,
    }).then((res) => {
      const { audio_buffer, text, id } = res
      streamData.value = {
        buffer: audio_buffer,
        text,
        id,
      }
      // aiè¿”å›çš„æ¶ˆæ¯ç»“æŸäº†
      if (isAiMessageEnd.value) {
        tempFormattedTexts.value = []
      }
      isAudioPlaying.value = true
    }).catch((error) => {
      isStreamPlaying.value = false
      isAudioPlaying.value = false
      console.log(error, 'é”™è¯¯')
    })
  }
  isStreamPlaying.value = true
}
/**
 * å‘é€æ¶ˆæ¯ç¡®è®¤æŒ‰é’®
 */
function handleConfirm() {
  tempBuffers.value = []
  //  ç‚¹å‡»æ—¶å¦‚æœaiæ¶ˆæ¯æ²¡æœ‰è¿”å›å®Œ ï¼Œå¹¶ä¸”æ­£åœ¨æ’­æ”¾ï¼Œç›´æ¥åœæ­¢
  if (isAiMessageEnd.value && isStreamPlaying.value) {
    stopAll()
    handleSendMsg()
    return
  }
  handleSendMsg()
}

function handleTouchStart() {
  if (loading.value) {
    stopAll()
  }

  textRes.value = ''
  handleRecorderTouchStart()
  // å¼€å§‹å½•éŸ³ï¼Œæ’å…¥ä¸€ä¸ªä¸´æ—¶æ¶ˆæ¯ï¼ˆå ä½ï¼‰
  const sendText = setAiContent({
    type: 'send',
    msg: '', // ç©ºæ¶ˆæ¯ä½œä¸ºå ä½
    modeName: modelName.value || '',
  })
  sendText.isRecordingPlaceholder = true // âœ… æ ‡è®°å ä½æ¶ˆæ¯

  content.value?.push(sendText)
  nextTick(() => {
    resetAndScrollToBottom()
  })
}

function handleTouchEnd() {
  handleRecorderTouchEnd().then(async () => {
    if (isRecorderClose.value) {
      // ç”¨æˆ·ä¸Šæ»‘å–æ¶ˆ
      removeLastUserMessage('user')
      replyForm.value = { content: '', role: 'user' }
    }
    else {
      // ç”¨æˆ·æ­£å¸¸æŠ¬èµ·
      if (textRes.value && textRes.value.trim() !== '') {
        // æœ‰è¯†åˆ«ç»“æœæ‰å‘é€
        const lastIndex = content.value.length - 1
        if (content.value[lastIndex]?.role === 'user') {
          content.value[lastIndex].content = textRes.value
        }
        handleConfirm()
        await nextTick()
        resetAndScrollToBottom() // å¼ºåˆ¶æ»šåŠ¨åˆ°åº•éƒ¨
      }
      else {
        removeLastUserMessage('user')
      }
    }
  }).finally(() => {
    iseRecorderTouchStart.value = false
  })
}

/**
 * aiæ¶ˆæ¯ç‚¹å‡»è¯­éŸ³
 * @warning ç”±äºè¯­éŸ³ç‚¹å‡»ä¹‹åæ’­æ”¾éŸ³é¢‘ä¼šæœ‰å»¶è¿Ÿï¼Œ æ‰€ä»¥åœ¨è¿™å„¿ç›´æ¥è®¾ç½®çŠ¶æ€
 */
const handleRecorder = debounce((text: string, index: number) => {
  // å½“å‰å·²ç»åœ¨æ’­æ”¾æ­¤æ¡æ¶ˆæ¯

  if (currentIndex.value === index && isStreamPlaying.value) {
    console.log('ğŸŸ¡ å†æ¬¡ç‚¹å‡»åŒä¸€æ¡ï¼Œæ‰§è¡Œåœæ­¢')
    streamPlayerRef.value?.onStreamStop()
    currentIndex.value = null
    return
  }

  if (!isStreamPlaying.value) {
    console.log('ğŸŸ¥ åˆ‡æ¢æ¶ˆæ¯æ’­æ”¾ï¼Œå…ˆåœæ­¢')
    streamPlayerRef.value?.onStreamStop()
    // stopChat()
  }

  // âœ… å¼€å§‹æ–°çš„æ’­æ”¾
  console.log('ğŸŸ¢ å¼€å§‹æ’­æ”¾æ–°æ¶ˆæ¯')
  currentIndex.value = index
  isStreamPlaying.value = true
  const longTexts = processText(text, true)
  longTexts.forEach((longText, i) => {
    doubaoSpeechSynthesisFormat({
      text: longText,
      id: i,
    }).then((res) => {
      const { audio_buffer, text, id } = res
      streamData.value = {
        buffer: audio_buffer,
        text,
        id,
      }
    }).catch(() => {
      isStreamPlaying.value = false
    })
  })
}, 500)

/**
 * è¯­éŸ³æ’­æ”¾çœŸæ­£çš„å¼€å§‹
 */
function onStreamPlayStart() {
  isAudioPlaying.value = true
}

/**
 * è¯­éŸ³æ’­æ”¾ç»“æŸ
 */
function onStreamPlayEnd() {
  isStreamPlaying.value = false
  isAudioPlaying.value = false
}
/**
 * è¯­éŸ³æ’­æ”¾åœæ­¢
 */
function onStreamStop() {
  isStreamPlaying.value = false
  isAudioPlaying.value = false
}

/**
 * æ ¹æ®è§’è‰²ç±»å‹åˆ é™¤æœ€åä¸€æ¡æ¶ˆæ¯
 */
function removeLastUserMessage(type: string) {
  const lastIndex = [...content.value].reverse().findIndex(item => item.role === type)
  if (lastIndex !== -1) {
    const realIndex = content.value.length - 1 - lastIndex
    content.value.splice(realIndex, 1)
  }
}

function handleClearContent() {
  if (content.value.length === 0) {
    return showToast('å½“å‰å¯¹è¯ä¸ºç©º')
  }
  if (loading.value) {
    stopAll()
  }

  showModal('æ˜¯å¦æ¸…ç©ºå¯¹è¯ï¼Ÿ').then(() => {
    content.value = []
    // åœæ­¢æ’­æ”¾
    if (isStreamPlaying.value) {
      streamPlayerRef.value?.onStreamStop()
    }
    // é‡ç½®æ ¼å¼åŒ–å™¨
    textReset()
  })
}

function stopAll() {
  // åœæ­¢aiæ¶ˆæ¯
  stopChat()
  // åœæ­¢æ’­æ”¾
  streamPlayerRef.value?.onStreamStop()
  currentIndex.value = null
  // é‡ç½®æ ¼å¼åŒ–å™¨
  textReset()
  // é‡ç½®æ’­æ”¾çŠ¶æ€
  isStreamPlaying.value = false
}

// æ·»åŠ ä¸€ä¸ªç›‘å¬æœ€åä¸€æ¡æ¶ˆæ¯å†…å®¹çš„å˜åŒ–ï¼ˆå¯¹äºæµå¼è¾“å‡ºéå¸¸æœ‰ç”¨ï¼‰
watch(
  () => content.value[content.value.length - 1]?.content,
  () => {
    if (content.value.length > 0) {
      nextTick(() => {
        scrollToBottom()
      })
      // æ£€æŸ¥æœ€åä¸€æ¡æ¶ˆæ¯æ˜¯å¦æ˜¯AIçš„å›å¤
      const lastMessage = content.value[content.value.length - 1]
      if (lastMessage?.role === 'assistant' && lastMessage?.streaming) {
        // è‡ªåŠ¨æ’­æ”¾
        autoPlayAiMessage(lastMessage.content || '', content.value.length - 1)
      }
    }
  },
)

watch(
  content.value,
  () => {
    nextTick(() => {
      scrollToBottom()
    })
  },
  { deep: true },
)

// ç›‘å¬è¯­éŸ³è¯†åˆ«å¼€å§‹å’Œç»“æŸ
watch(() => isRunning.value, (val: boolean) => {
  if (val) {
    animatedDots.value = '.'
    dotTimer = setInterval(() => {
      animatedDots.value = animatedDots.value.length >= 3 ? '.' : `${animatedDots.value}.`
    }, 500)
  }
  else {
    if (dotTimer)
      clearInterval(dotTimer)
    dotTimer = null
    animatedDots.value = ''
  }
})

watch(() => textRes.value, async (newVal) => {
  await nextTick() // ç¡®ä¿è§†å›¾æ›´æ–°å®Œæˆ
  replyForm.value.content = newVal as string
  console.log('æ–‡æœ¬å†…å®¹èµ‹å€¼æ›´æ–°ï¼š', newVal)
})

onMounted(() => {
  (vueInstance as any).isMounted = true
  RecordAppInstance.UniPageOnShow(vueInstance)
  recReq().then((res) => {
    console.log(res, 'è¯·æ±‚æƒé™å…è®¸')
    isFirstVisit.value = false
  }).catch((err) => {
    showToastError(err)
    console.log(err, 'è¯·æ±‚æƒé™æ‹’ç»')
  })

  initHeights()
})

onShow(() => {
  if ((vueInstance as any)?.isMounted) {
    RecordAppInstance.UniPageOnShow(vueInstance)
  }
})

router.ready(() => {
  const { modelName } = router.query as any
  console.log(modelName, 'è·¯ç”±å‚æ•°')

  if (modelName) {
    handleChangeAiModel(modelName)
  }
})
</script>

<template>
  <view>
    <nav-bar>
      <template #right>
        <view class="flex  pr-50rpx">
          <icon-font name="clear" color="#E95655" size="40" @click="handleClearContent" />
          <icon-font :name="isAutoPlayAiMessage ? 'sound' : 'mute'" :color="isAutoPlayAiMessage ? COLOR_PRIMARY : ''" size="40" class="ml-20rpx" @click="isAutoPlayAiMessage = !isAutoPlayAiMessage" />
        </view>
      </template>

      <text @click="handleMultiClick">
        æŸ¯ä»”AI
      </text>
    </nav-bar>

    <!-- æµå¼æµå¼aiæ¶ˆæ¯ -->
    <GaoChatSSEClient
      ref="chatSSEClientRef"
      @on-open="onStart"
      @on-error="onError"
      @on-message="onSuccess && onSuccess?.($event)"
      @on-finish="onFinish"
    />

    <!-- éŸ³é¢‘æ’­æ”¾ç»„ä»¶ -->
    <!-- #ifdef APP-PLUS -->
    <StreamPlayer
      ref="streamPlayerRef"
      :stream-data="streamData"
      @on-stream-play-start="onStreamPlayStart"
      @on-stream-play-end="onStreamPlayEnd"
      @on-stream-stop="onStreamStop"
    />
    <!-- #endif -->

    <view :style="aiPageContent">
      <view
        class="absolute top-0 left-0 w-full h-full z-0 flex justify-center pointer-events-none"
        :style="{ 'padding-top': pageHeight }"
      >
        <image
          :src="(isStreamPlaying && isAudioPlaying) ? '/static/images/aiPageBg.gif' : '/static/images/aiPageBg-quiet.png'"
          mode="aspectFit"
          class="aiPageBg-img"
        />
      </view>

      <scroll-view
        ref="scrollViewRef"
        scroll-y
        :scroll-top="scrollTop"
        class=" scroll-view pr-20rpx pl-20rpx  block h-full"
        :scroll-with-animation="true"
        :style="aiScrollView"
        @scroll="handleScroll"
        @scrolltolower="scrolltolower"
      >
        <view class="scroll-content">
          <view v-if="content.length === 0" class="h-full flex justify-end flex-col items-center pb-200rpx pt-500rpx">
            <view>
              <image
                class="ai-img"
                :src="`/static/images/${currentModel?.icon}.png`"
                mode="aspectFill"
              />
            </view>
            <view class="font-size-60rpx mt-20rpx">
              æˆ‘æ˜¯{{ modelName }}
            </view>
            <view class="mt-20rpx w-80%">
              æˆ‘å¯ä»¥å¸®ä½ æœç´¢ã€ç­”ç–‘ã€å†™ä½œã€è¯·åœ¨ä¸‹æ–¹è¾“å…¥ä½ çš„å†…å®¹~
            </view>
          </view>

          <view v-for="(msg, index) in content" :key="index" class="py-16rpx">
            <!-- ç”¨æˆ·æ¶ˆæ¯ -->
            <view v-if="msg.role === 'user'" class=" flex  flex-justify-end opacity-60">
              <view class="message-bubble p-32rpx border-rd-16rpx   bg-#07c160 color-white max-w-80%">
                <text>
                  {{
                    msg.isRecordingPlaceholder
                      ? (textRes || '') + (isRunning && textRes ? animatedDots : '')
                      : Array.isArray(msg.content)
                        ? msg.content[0].text
                        : msg.content
                  }}
                </text>
                <!-- æµå¼åŠ è½½åŠ¨ç”» -->
                <view v-if="msg.isRecordingPlaceholder && !textRes" class="flex-center">
                  <uni-load-more icon-type="auto" status="loading" :show-text="false" />
                </view>
              </view>
            </view>

            <!-- AIæ¶ˆæ¯ï¼ˆå«åŠ è½½çŠ¶æ€ï¼‰ -->
            <view v-else class="flex justify-start opacity-60">
              <Icon-font name="zhipu" class="mt-20rpx mr-10rpx" />
              <view class="flex mt-16rpx mb-16rpx flex-justify-start bg-#ffffff color-#333333 max-w-80% border-rd-16rpx">
                <view
                  class="message-bubble  p-32rpx border-rd-16rpx w-100%"
                  :class="[msg.streaming && !(msg.content && msg.content.length) ? 'flex-center w-120rpx h-120rpx ' : '']"
                >
                  <view v-if="msg.content">
                    <UaMarkdown :source="msg.content" :show-line="false" />
                    <view class="h-2rpx  bg-black-3 my-10rpx" />

                    <view class="flex items-center justify-end ">
                      <view class="border-rd-16rpx size-60rpx bg-#e8ecf5 flex-center" @click="handleCopy(msg.content)">
                        <icon-font name="copy" :color="COLOR_PRIMARY" :size="28" />
                      </view>
                      <view class="border-rd-16rpx size-60rpx  bg-#e8ecf5 flex-center  ml-20rpx" @click="handleRecorder(msg.content, index)">
                        <audio-wave v-if="isStreamPlaying && currentIndex === index" :color="COLOR_PRIMARY" />
                        <icon-font v-else name="sound" :color="COLOR_PRIMARY" :size="28" />
                      </view>
                    </view>
                  </view>
                  <!-- æµå¼åŠ è½½åŠ¨ç”» -->
                  <view v-if=" msg.streaming && !(msg.content && msg.content.length)" class="flex-center">
                    <uni-load-more icon-type="auto" status="loading" :show-text="false" />
                  </view>
                </view>
              </view>
            </view>
          </view>
        </view>
      </scroll-view>
    </view>

    <!-- ç»Ÿä¸€è¾“å…¥æ¡† -->
    <RecorderInput
      v-model:model-value="replyForm.content"
      v-model:focus="isFocus"
      v-model:show-recording-button="showRecordingButton"
      placeholder="è¯·è¾“å…¥æ‚¨çš„é—®é¢˜..."
      class="flex-1"
      btn-text="å‘é€"
      @recorder-close="handleRecorderClose"
      @show-recorder="handleShowRecorder"
      @recorder-touch-start="handleTouchStart"
      @recorder-touch-end="handleTouchEnd"
      @recorder-confirm="handleRecorderConfirm"
      @confirm="handleConfirm "
    />
  </view>
</template>

<style lang="scss">
.message-bubble {
  box-shadow: 0 2px 4px rgba(0, 0, 0, 0.1);
}
.ai-img {
  width: 160rpx;
  height: 160rpx;
}
</style>

<route lang="json">
  {
       "style": { "navigationBarTitleText": "å½•éŸ³","navigationStyle": "custom" }
  }
</route>
