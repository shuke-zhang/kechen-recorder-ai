<!-- eslint-disable ts/ban-ts-comment -->
<!-- eslint-disable import/no-duplicates -->
 <!-- #ifdef APP-PLUS -->
<script module="recorderCore" lang="renderjs">
// @ts-ignore
import Recorder from 'recorder-core'
import 'recorder-core/src/extensions/buffer_stream.player.js'

import RecordApp from 'recorder-core/src/app-support/app'
// import '../../../../uni_modules/Recorder-UniCore/app-uni-support.js'
import '../../../uni_modules/Recorder-UniCore/app-uni-support.js'
import 'recorder-core/src/engine/pcm'
import 'recorder-core/src/extensions/waveview'
// @ts-ignore

export default {
  data() {
    return {
    }
  },

  mounted() {
    // Appçš„renderjså¿…é¡»è°ƒç”¨çš„å‡½æ•°ï¼Œä¼ å…¥å½“å‰æ¨¡å—this
    RecordApp.UniRenderjsRegister(this)
  },
  methods: {
    // è¿™é‡Œå®šä¹‰çš„æ–¹æ³•ï¼Œåœ¨é€»è¾‘å±‚ä¸­å¯é€šè¿‡ RecordApp.UniWebViewVueCall(this,'this.xxxFunc()') ç›´æ¥è°ƒç”¨
    // è°ƒç”¨é€»è¾‘å±‚çš„æ–¹æ³•ï¼Œè¯·ç›´æ¥ç”¨ this.$ownerInstance.callMethod("xxxFunc",{args}) è°ƒç”¨ï¼ŒäºŒè¿›åˆ¶æ•°æ®éœ€è½¬æˆbase64æ¥ä¼ é€’
  },
}
</script>
<!-- #endif -->

<!-- eslint-disable import/first, import/order, import/no-named-default,import/no-duplicates -->
<script setup lang='ts'>
import type StreamPlayer from '@/components/StreamPlayer/StreamPlayer.vue'
import { NAV_BAR_HEIGHT, getStatusBarHeight } from '@/components/nav-bar/nav-bar'
import { default as RecorderInstance } from 'recorder-core'
import { default as RecordAppInstance } from 'recorder-core/src/app-support/app'
import { useTextFormatter } from './hooks/useTextFormatter'
import RecorderInput from './recorder-input.vue'
import useRecorder from './hooks/useRecorder'
import useAiPage from './hooks/useAiPage'
import useAutoScroll from './hooks/useAutoScroll'
import { doubaoSpeechSynthesisFormat } from '@/api/audio'
import '../../../uni_modules/Recorder-UniCore/app-uni-support.js'
/** éœ€è¦ç¼–è¯‘æˆå¾®ä¿¡å°ç¨‹åºæ—¶ï¼Œå¼•å…¥å¾®ä¿¡å°ç¨‹åºæ”¯æŒæ–‡ä»¶ */
// #ifdef MP-WEIXIN
import 'recorder-core/src/app-support/app-miniProgram-wx-support.js'
// #endif

// #ifdef H5 || MP-WEIXIN
import 'recorder-core/src/engine/pcm'
import 'recorder-core/src/extensions/waveview'
// #endif
const vueInstance = getCurrentInstance()?.proxy as any // å¿…é¡»å®šä¹‰åˆ°æœ€å¤–é¢ï¼ŒgetCurrentInstanceå¾—åˆ°çš„å°±æ˜¯å½“å‰å®ä¾‹this
const pageHeight = computed(() => {
  return `${getStatusBarHeight() + NAV_BAR_HEIGHT + 1}px`
})
/**
 * éŸ³é¢‘æ˜¯å¦æ­£åœ¨æ’­æ”¾
 */
const isStreamPlaying = ref(false)
const router = useRouter<{
  modelName: string
}>()

/**
 * éŸ³é¢‘æ’­æ”¾ç»„ä»¶å®ä¾‹
 */
const streamPlayerRef = ref<InstanceType<typeof StreamPlayer>>()
// const { handleMultiClick } = useMultiClickTrigger({
//   onTrigger: () => {
//     router.push('/pages/test/index', { id: 123 })
//   },
// })

const {
  chatSSEClientRef,
  content,
  isAiMessageEnd,
  loading,
  modelName,
  modelSubTitle,
  modelPrefix,
  currentModel,
  replyForm,
  aiPageContent,
  onSuccess,
  onFinish,
  stopChat,
  onStart,
  onError,
  handleChangeAiModel,
  handleSendMsg,
  handleCopy,
  setAiContent,
} = useAiPage(pageHeight.value)

const {
  textRes,
  isFocus,
  iseRecorderTouchStart,
  isRecorderClose,
  isRunning,
  isFirstVisit,
  showRecordingButton,
  recReq,
  handleRecorderClose,
  handleShowRecorder,
  handleRecorderTouchStart,
  handleRecorderTouchEnd,
  handleRecorderConfirm,
} = useRecorder({
  RecordApp: RecordAppInstance,
  Recorder: RecorderInstance,
  vueInstance,
})

const {
  scrollTop,
  handleScroll,
  resetAndScrollToBottom,
  initHeights,
  scrollToBottom,
  scrolltolower,
} = useAutoScroll({
  contentList: content,
  vueInstance,
  scrollViewSelector: '.scroll-view',
  scrollContentSelector: '.scroll-content',
  immediate: true,
})

const { processText, textReset } = useTextFormatter()

const scrollViewRef = ref(null)
const animatedDots = ref('')
let dotTimer: NodeJS.Timeout | null = null
const currentIndex = ref<number | null>(null)
const isAudioPlaying = ref(false) // éŸ³é¢‘æ’­æ”¾çœŸæ­£çš„å¼€å§‹
const tempBuffers = ref<{ audio_data: string, text: string }[]>([])
const tempFormattedTexts = ref<string[]>([])
const streamData = ref<{
  text: string
  buffer: string
  id: number
}>()
// æ˜¯å¦åˆ‡æ¢åˆ°æ–°çš„æ¶ˆæ¯è¿›è¡Œæ’­æ”¾
const isSwitchingNewMessage = ref(false)

/**
 * æ˜¯å¦è‡ªåŠ¨æ’­æ”¾
 */
const isAutoPlayAiMessage = ref(true)
// å…¨å±€å˜é‡å­˜å‚¨æ ¼å¼åŒ–å™¨å®ä¾‹å’Œå½“å‰å¤„ç†çš„æ¶ˆæ¯ç´¢å¼•
let lastProcessedIndex: number | null = null
/** ä»£è¡¨å½“ç‚¹å‡»äº†éŸ³é¢‘å°å›¾æ ‡æ—¶ ï¼Œå¦‚æœæ­¤æ—¶aiæ¶ˆæ¯è¿˜æ²¡å›å¤å®ŒéŸ³é¢‘ä¹Ÿåœ¨æ’­æ”¾æ—¶ä¸ºtrue å¦åˆ™ä¸ºfalse ä¸»è¦æ˜¯ç”¨äºåˆ¤æ–­aiå›å¤ä¸­ç‚¹å‡»äº†éŸ³é¢‘å›¾æ ‡åä¸å†éœ€è¦è‡ªåŠ¨æ’­æ”¾ */
const hasUserInterruptedAutoPlay = ref(false)
const lastAiMsgEnd = ref(false)

/**
 * aiå†…å®¹è‡ªåŠ¨æ’­æ”¾éŸ³é¢‘
 */
async function autoPlayAiMessage(_text: string, index: number) {
  //
  // if (!isAutoPlayAiMessage.value || hasUserInterruptedAutoPlay.value)
  if (!isAutoPlayAiMessage.value) {
    return
  }

  // if (!isApp)
  //   return
  // è®¾ç½®å½“å‰æ’­æ”¾çš„æ¶ˆæ¯ç´¢å¼•
  currentIndex.value = index

  // å¦‚æœæ˜¯æ–°çš„æ¶ˆæ¯ï¼Œé‡ç½®æ ¼å¼åŒ–å™¨
  if (currentIndex.value !== lastProcessedIndex) {
    textReset()
    lastProcessedIndex = currentIndex.value
  }
  // å¼€å§‹è¯­éŸ³åˆæˆå¹¶æ’­æ”¾
  const longText = processText({
    text: _text,
    isFullText: false,
    forceFlush: isAiMessageEnd.value,
  })

  // å¤„ç†æ–‡æœ¬ ä¸‹é¢æ˜¯å¯¹æ¥åç«¯çš„éŸ³é¢‘ é‡‡ç”¨æ¥å£çš„æ–¹å¼
  if (longText.length > 0) {
    tempFormattedTexts.value.push(longText)

    //  åˆ¤æ–­æ˜¯ä¸æ˜¯æ–°çš„aiæ¶ˆæ¯
    if (tempFormattedTexts.value.findIndex(t => t === longText) === 0 && !isAiMessageEnd.value) {
      streamPlayerRef.value?.onStreamStop()
    }

    doubaoSpeechSynthesisFormat({
      text: longText,
      id: tempFormattedTexts.value.findIndex(t => t === longText) || 0,
    }, tempFormattedTexts.value.findIndex(t => t === longText) === 0).then((res) => {
      const { audio_buffer, text, id } = res
      streamData.value = {
        buffer: audio_buffer,
        text,
        id,
      }
      // aiè¿”å›çš„æ¶ˆæ¯ç»“æŸäº†
      if (isAiMessageEnd.value) {
        tempFormattedTexts.value = []
        hasUserInterruptedAutoPlay.value = false
      }
    }).catch((error) => {
      isStreamPlaying.value = false
      isAudioPlaying.value = false
      console.log(error, 'é”™è¯¯')
    })
  }
  isStreamPlaying.value = true
}

// function handleAutoPlayAiMessage() {
//   isAutoPlayAiMessage.value = !isAutoPlayAiMessage.value
//   if (!isAutoPlayAiMessage.value) {
//     hasUserInterruptedAutoPlay.value = false
//     // ç›´æ¥åœæ­¢æ’­æ”¾éŸ³é¢‘
//     streamPlayerRef.value?.onStreamStop()
//     isStreamPlaying.value = false
//   }
// }

function userMsgFormat(prefix: string, text: string, isFormat = true) {
  if (!isFormat)
    return text
  const index = text.indexOf(prefix)
  if (index === -1)
    return text // æ²¡æœ‰å‰ç¼€å°±è¿”å›åŸå†…å®¹
  return text.slice(index + prefix.length)
}

/**
 * å‘é€æ¶ˆæ¯ç¡®è®¤æŒ‰é’®
 */
async function handleConfirm() {
  streamPlayerRef.value?.onStreamStop()
  tempFormattedTexts.value = []
  tempBuffers.value = []
  removeEmptyMessagesByRole('assistant') // ç§»é™¤assistantè§’è‰²çš„ç©ºæ¶ˆæ¯

  //  ç‚¹å‡»æ—¶å¦‚æœaiæ¶ˆæ¯æ²¡æœ‰è¿”å›å®Œ ï¼Œå¹¶ä¸”æ­£åœ¨æ’­æ”¾ï¼Œç›´æ¥åœæ­¢
  if ((!isAiMessageEnd.value && loading.value) || isStreamPlaying.value) {
    await stopAll()
    // åœæ­¢éŸ³é¢‘æ’­æ”¾
    handleSendMsg()
    return
  }

  handleSendMsg()
}

const startTime = ref(0)
const handleTouchStart = debounce(() => {
  console.log('ğŸŸ¢ å¼€å§‹å½•éŸ³')
  removeEmptyMessagesByRole('assistant')
  startTime.value = Date.now()
  stopAll()
  textRes.value = ''
  handleRecorderTouchStart()
  // å¼€å§‹å½•éŸ³ï¼Œæ’å…¥ä¸€ä¸ªä¸´æ—¶æ¶ˆæ¯ï¼ˆå ä½ï¼‰
  const sendText = setAiContent({
    type: 'send',
    msg: '', // ç©ºæ¶ˆæ¯ä½œä¸ºå ä½
    modeName: modelName.value || '',
  })
  sendText.isRecordingPlaceholder = true // âœ… æ ‡è®°å ä½æ¶ˆæ¯

  content.value?.push(sendText)
  nextTick(() => {
    resetAndScrollToBottom()
  })
}, 300)

function onTouchEnd() {
  console.log('ğŸ”´ å½•éŸ³æŒ‰é’®æŠ¬èµ·')

  handleRecorderTouchEnd().then(async () => {
    const endTime = Date.now()
    const duration = endTime - startTime.value

    if (duration < 300) {
      removeEmptyMessagesByRole('user')
      showToastError('è¯´è¯æ—¶é—´å¤ªçŸ­')
      stopAll() // âœ… å¼ºåˆ¶å…³é—­æ‰€æœ‰é€»è¾‘
      return
    }
    if (isRecorderClose.value) {
      // ç”¨æˆ·ä¸Šæ»‘å–æ¶ˆ
      removeEmptyMessagesByRole('user')
      replyForm.value = { content: '', role: 'user' }
    }
    else {
      // ç”¨æˆ·æ­£å¸¸æŠ¬èµ·
      if (textRes.value && textRes.value.trim() !== '') {
        // æœ‰è¯†åˆ«ç»“æœæ‰å‘é€
        const lastIndex = content.value.length - 1
        if (content.value[lastIndex]?.role === 'user') {
          content.value[lastIndex].content = textRes.value
        }
        handleConfirm()
        await nextTick()
        resetAndScrollToBottom() // å¼ºåˆ¶æ»šåŠ¨åˆ°åº•éƒ¨
      }
      else {
        showToastError('æœªè¯†åˆ«åˆ°å†…å®¹')
        removeEmptyMessagesByRole('user')
      }
    }
  }).finally(() => {
    iseRecorderTouchStart.value = false
  })
}

const handleTouchEnd = debounce(() => {
  onTouchEnd()
}, 500)

/**
 * aiæ¶ˆæ¯ç‚¹å‡»è¯­éŸ³
 * @warning ç”±äºè¯­éŸ³ç‚¹å‡»ä¹‹åæ’­æ”¾éŸ³é¢‘ä¼šæœ‰å»¶è¿Ÿï¼Œ æ‰€ä»¥åœ¨è¿™å„¿ç›´æ¥è®¾ç½®çŠ¶æ€
 */
const handleRecorder = debounce((text: string, index: number) => {
  // å¦‚æœ AI æ¶ˆæ¯è¿˜åœ¨å›å¤ä¸­ï¼Œæ ‡è®°ç”¨æˆ·ä¸­æ–­è‡ªåŠ¨æ’­æ”¾
  if (!isAiMessageEnd.value) {
    hasUserInterruptedAutoPlay.value = true
  }
  // å½“å‰å·²ç»åœ¨æ’­æ”¾æ­¤æ¡æ¶ˆæ¯
  if (currentIndex.value === index && isStreamPlaying.value) {
    console.log('ğŸŸ¡ å†æ¬¡ç‚¹å‡»åŒä¸€æ¡ï¼Œæ‰§è¡Œåœæ­¢')
    streamPlayerRef.value?.onStreamStop()
    currentIndex.value = null
    isStreamPlaying.value = false
    return
  }

  // å¦‚æœæ­£åœ¨æ’­æ”¾ä¸”æ˜¯æ–°çš„æ¶ˆæ¯ï¼Œå…ˆåœæ­¢å½“å‰æ’­æ”¾
  if (currentIndex.value !== null && isStreamPlaying.value) {
    isSwitchingNewMessage.value = true
    console.log('ğŸ”´ åˆ‡æ¢æ–°æ¶ˆæ¯ï¼Œå…ˆåœæ­¢å·²æ’­æ”¾çš„æ¶ˆæ¯')
    streamPlayerRef.value?.onStreamStop()
    isStreamPlaying.value = false
  }

  // âœ… å¼€å§‹æ–°çš„æ’­æ”¾
  console.log('ğŸŸ¢ å¼€å§‹æ’­æ”¾æ–°æ¶ˆæ¯')
  isStreamPlaying.value = true
  currentIndex.value = index

  const longTexts = processText({
    text,
    isFullText: true,
  })

  longTexts.forEach((longText, i) => {
    if (longText.length) {
      doubaoSpeechSynthesisFormat({
        text: longText,
        id: i,
      }).then((res) => {
        const { audio_buffer, text, id } = res
        streamData.value = {
          buffer: audio_buffer,
          text,
          id,
        }
      }).catch((e) => {
        console.log('ç‚¹å‡»æ—¶æ•è·åˆ°é”™è¯¯', e)
        isStreamPlaying.value = false
        currentIndex.value = null
      })
    }
  })
}, 500)

/**
 * è¯­éŸ³æ’­æ”¾çœŸæ­£çš„å¼€å§‹
 */
function onStreamPlayStart() {
  isAudioPlaying.value = true
  // é˜²æ­¢ç”±äºæ’­æ”¾å™¨åœæ­¢æ—¶è§¦å‘å»¶è¿Ÿï¼Œæ‰€ä»¥è¿™å„¿ä¹Ÿè¦è®¾ç½®çŠ¶æ€
  isStreamPlaying.value = true
}

/**
 * è¯­éŸ³æ’­æ”¾ç»“æŸ
 */
function onStreamPlayEnd() {
  /**
   * è¿™å„¿ä½¿ç”¨  isSwitchingNewMessage æ¥æ§åˆ¶ç«‹å³æ›´æ–° isStreamPlaying çš„çŠ¶æ€çš„
   * å·²çŸ¥å½“æˆ‘å‰å‡ åˆ‡æ¢æ–°çš„æ¶ˆæ¯æ’­æ”¾æ—¶ ï¼Œ ä¼šè§¦å‘è¯¥å‡½æ•°ï¼Œæ­¤æ—¶ä¼šå…³é—­ isStreamPlaying çš„çŠ¶æ€
   * æ­¤æ—¶ isSwitchingNewMessage çš„çŠ¶æ€å°±ä¸æ˜¯åœ¨æˆ‘ç‚¹å‡»åç«‹å³è§¦å‘äº†ï¼Œè€Œæ˜¯åœ¨éŸ³é¢‘æ’­æ”¾æ—¶æ‰è§¦å‘ï¼Œè¿™ä¼šé€ æˆè§‚çœ‹ä¸Šçš„å»¶è¿Ÿ
   * æ‰€ä»¥åœ¨è¿™å„¿ä½¿ç”¨ isSwitchingNewMessage æ¥æ§åˆ¶ç«‹å³æ›´æ–° isStreamPlaying çš„çŠ¶æ€çš„
   */
  if (isSwitchingNewMessage.value) {
    isSwitchingNewMessage.value = false
  }
  else {
    isStreamPlaying.value = false
    currentIndex.value = null
  }
  isAudioPlaying.value = false
}
/**
 * è¯­éŸ³æ’­æ”¾åœæ­¢
 */
function onStreamStop() {
  isStreamPlaying.value = false
  isAudioPlaying.value = false
  currentIndex.value = null
}

/**
 * æ ¹æ®è§’è‰²ç±»å‹åˆ é™¤æœ€åä¸€æ¡æ¶ˆæ¯
 */
function removeEmptyMessagesByRole(type: string) {
  for (let i = content.value.length - 1; i >= 0; i--) {
    const item = content.value[i]
    const raw = item.content
    const text = Array.isArray(raw) ? raw[0]?.text ?? '' : raw ?? ''

    const isEmpty = typeof text === 'string' && text.trim() === ''
    if (item.role === type && isEmpty) {
      content.value.splice(i, 1)
    }
  }
}

async function stopAll() {
  console.log('ğŸš« å¼ºåˆ¶å…³é—­æ‰€æœ‰é€»è¾‘')
  // åœæ­¢aiå›å¤çš„æ¶ˆæ¯
  await stopChat.value()
  // åœæ­¢éŸ³é¢‘æ’­æ”¾
  await streamPlayerRef.value?.onStreamStop()
  currentIndex.value = null
  // é‡ç½®æ ¼å¼åŒ–å™¨
  textReset()
  // é‡ç½®æ’­æ”¾çŠ¶æ€
  isStreamPlaying.value = false
  // é‡ç½®éŸ³é¢‘æ’­æ”¾çœŸæ­£çš„çŠ¶æ€
  isAudioPlaying.value = false
}
/** è·³è½¬åˆ°è®¾ç½®é¡µé¢ */
// function handleToSetting() {
//   router.replace('/pages/mine/index')
// }

// æ·»åŠ ä¸€ä¸ªç›‘å¬æœ€åä¸€æ¡æ¶ˆæ¯å†…å®¹çš„å˜åŒ–ï¼ˆå¯¹äºæµå¼è¾“å‡ºéå¸¸æœ‰ç”¨ï¼‰
watch(
  () => content.value[content.value.length - 1]?.content,
  () => {
    if (content.value.length > 0) {
      nextTick(() => {
        scrollToBottom()
      })

      // æ£€æŸ¥æœ€åä¸€æ¡æ¶ˆæ¯æ˜¯å¦æ˜¯AIçš„å›å¤
      const lastMessage = content.value[content.value.length - 1]
      if (lastMessage?.role === 'assistant' && lastMessage?.streaming) {
        // è‡ªåŠ¨æ’­æ”¾
        autoPlayAiMessage(lastMessage.content as string || ' ', content.value.length - 1)
      }
    }
  },
)

watch(() => isAiMessageEnd.value, (newVal) => {
  if (newVal) {
    lastAiMsgEnd.value = true
    tempFormattedTexts.value = []
    hasUserInterruptedAutoPlay.value = false
  }
})

watch(
  content.value,
  () => {
    nextTick(() => {
      scrollToBottom()
    })
  },
  { deep: true },
)

// ç›‘å¬è¯­éŸ³è¯†åˆ«å¼€å§‹å’Œç»“æŸ
watch(() => isRunning.value, (val: boolean) => {
  if (val) {
    animatedDots.value = '.'
    dotTimer = setInterval(() => {
      animatedDots.value = animatedDots.value.length >= 3 ? '.' : `${animatedDots.value}.`
    }, 500)
  }
  else {
    if (dotTimer)
      clearInterval(dotTimer)
    dotTimer = null
    animatedDots.value = ''
  }
})

watch(() => textRes.value, async (newVal) => {
  await nextTick() // ç¡®ä¿è§†å›¾æ›´æ–°å®Œæˆ
  replyForm.value.content = modelPrefix.value + newVal as string
})

watch(() => replyForm.value.content, (newVal) => {
})

onMounted(() => {
  (vueInstance as any).isMounted = true
  RecordAppInstance.UniPageOnShow(vueInstance)
  recReq().then((res) => {
    console.log(res, 'è¯·æ±‚æƒé™å…è®¸')
    isFirstVisit.value = false
  }).catch((err) => {
    showToastError(err)
    console.log(err, 'è¯·æ±‚æƒé™æ‹’ç»')
  })

  initHeights()
})

onShow(() => {
  if ((vueInstance as any)?.isMounted) {
    RecordAppInstance.UniPageOnShow(vueInstance)
  }
})

router.ready(() => {
  handleChangeAiModel()
})
</script>

<template>
  <view>
    <!-- <nav-bar :show-back="false">
      <template #left>
        <view>
          <icon-font :name="isAutoPlayAiMessage ? 'sound' : 'mute'" :color="isAutoPlayAiMessage ? COLOR_PRIMARY : ''" size="40" class="ml-20rpx" @click="handleAutoPlayAiMessage" />
        </view>
      </template>

      <template #right>
        <view class="flex  pr-50rpx">
          <icon-font name="setting" color="#000" size="40" @click="handleToSetting" />
        </view>
      </template>

      <text @click="handleMultiClick">
        æŸ¯ä»”AI
      </text>
    </nav-bar> -->

    <!-- æµå¼æµå¼aiæ¶ˆæ¯ -->
    <GaoChatSSEClient
      ref="chatSSEClientRef"
      @on-open="onStart"
      @on-error="onError"
      @on-message="onSuccess && onSuccess?.($event)"
      @on-finish="onFinish"
    />

    <!-- éŸ³é¢‘æ’­æ”¾ç»„ä»¶ -->
    <!-- #ifdef APP-PLUS -->
    <StreamPlayer
      ref="streamPlayerRef"
      :stream-data="streamData"
      @on-stream-play-start="onStreamPlayStart"
      @on-stream-play-end="onStreamPlayEnd"
      @on-stream-stop="onStreamStop"
    />
    <!-- #endif -->

    <view :style="aiPageContent">
      <view
        class="  w-full h-72%   pointer-events-none"
      >
        <image
          :src="(isStreamPlaying && isAudioPlaying) ? '/static/images/aiPageBg.gif' : '/static/images/aiPageBg-quiet.png'"
          mode="aspectFit"
          class="size-100%"
        />
      </view>

      <view class="h-28% ">
        <scroll-view
          ref="scrollViewRef"
          scroll-y
          :scroll-top="scrollTop"
          class=" scroll-view pr-20rpx pl-20rpx  h-full"
          :scroll-with-animation="true"
          @scroll="handleScroll"
          @scrolltolower="scrolltolower"
        >
          <view class="scroll-content">
            <view v-if=" content.length === 0" class="h-full flex justify-end flex-col items-center ">
              <view>
                <image
                  class="ai-img"
                  :src="`/static/images/ai-logo/${currentModel?.icon}.png`"
                  mode="aspectFill"
                />
              </view>
              <view class="font-size-60rpx mt-20rpx">
                æˆ‘æ˜¯{{ modelSubTitle }}
              </view>
              <view class="mt-20rpx w-80%">
                æˆ‘å¯ä»¥å¸®ä½ æœç´¢ã€ç­”ç–‘ã€å†™ä½œã€è¯·åœ¨ä¸‹æ–¹è¾“å…¥ä½ çš„å†…å®¹~
              </view>
            </view>

            <view v-for="(msg, index) in content" :key="index" class="py-16rpx">
              <!-- ç”¨æˆ·æ¶ˆæ¯ -->
              <view v-if="msg.role === 'user'" class=" flex  flex-justify-end opacity-60">
                <view class="message-bubble p-32rpx border-rd-16rpx   bg-#07c160 color-white max-w-80%">
                  <text selectable>
                    <!-- é¦–å…ˆåˆ¤æ–­ ç”¨æˆ·æ¶ˆæ¯ä¸´æ—¶åŠ è½½çŠ¶æ€ å¦‚æœæ˜¯åˆ™ä»£è¡¨æ˜¯è¯­éŸ³è¯†åˆ«æ¶ˆæ¯ å¦åˆ™å±•ç¤ºå·²ç»æ·»åŠ è¿›å»çš„æ¶ˆæ¯ -->
                    {{
                      msg.isRecordingPlaceholder
                        ? (textRes || '') + (isRunning && textRes ? animatedDots : '')
                        : Array.isArray(msg.content)
                          ? userMsgFormat(modelPrefix, (msg.content as any)[0].text, true)
                          : userMsgFormat(modelPrefix, msg.content || '', true)
                    }}
                  </text>
                  <!-- æµå¼åŠ è½½åŠ¨ç”» -->
                  <view v-if="msg.isRecordingPlaceholder && !textRes" class="flex-center">
                    <uni-load-more icon-type="auto" status="loading" :show-text="false" />
                  </view>
                </view>
              </view>

              <!-- AIæ¶ˆæ¯ï¼ˆå«åŠ è½½çŠ¶æ€ï¼‰ -->
              <view v-if="msg.role === 'assistant'" class="flex justify-start opacity-60">
                <Icon-font name="zhipu" class="mt-20rpx mr-10rpx" />
                <view class="flex mt-16rpx mb-16rpx flex-justify-start bg-#ffffff color-#333333 max-w-80% border-rd-16rpx">
                  <view
                    class="message-bubble  p-32rpx border-rd-16rpx w-100%"
                    :class="[msg.streaming && !(msg.content && msg.content!.length) ? 'flex-center w-120rpx h-120rpx ' : '']"
                  >
                    <view v-if="msg.content">
                      <UaMarkdown :source="`${msg.content}`" :show-line="false" />

                      <view class="h-2rpx  bg-black-3 my-10rpx" />

                      <view class="flex items-center justify-end ">
                        <view class="border-rd-16rpx size-60rpx bg-#e8ecf5 flex-center" @click="handleCopy(msg.content as string)">
                          <icon-font name="copy" :color="COLOR_PRIMARY" :size="28" />
                        </view>
                        <view class="border-rd-16rpx size-60rpx  bg-#e8ecf5 flex-center  ml-20rpx" @click="handleRecorder(msg.content as string, index)">
                          <audio-wave v-if="isStreamPlaying && currentIndex === index" :color="COLOR_PRIMARY" />
                          <icon-font v-else name="sound" :color="COLOR_PRIMARY" :size="28" />
                        </view>
                      </view>
                    </view>
                    <!-- æµå¼åŠ è½½åŠ¨ç”» -->
                    <view v-if=" msg.streaming && !(msg.content && msg.content!.length)" class="flex-center">
                      <uni-load-more icon-type="auto" status="loading" :show-text="false" />
                    </view>
                  </view>
                </view>
              </view>
            </view>
          </view>
        </scroll-view>
      </view>
    </view>

    <!-- ç»Ÿä¸€è¾“å…¥æ¡† -->
    <RecorderInput
      v-model:model-value="replyForm.content"
      v-model:focus="isFocus"
      v-model:show-recording-button="showRecordingButton"
      placeholder="è¯·è¾“å…¥æ‚¨çš„é—®é¢˜..."
      btn-text="å‘é€"
      @recorder-close="handleRecorderClose"
      @show-recorder="handleShowRecorder"
      @recorder-touch-start="handleTouchStart"
      @recorder-touch-end="handleTouchEnd"
      @recorder-confirm="handleRecorderConfirm"
      @confirm="handleConfirm "
    />
  </view>
</template>

<style lang="scss">
.message-bubble {
  box-shadow: 0 2px 4px rgba(0, 0, 0, 0.1);
}
.ai-img {
  width: 160rpx;
  height: 160rpx;
}
</style>

<route lang="json" pages="page">
  {
       "style": { "navigationBarTitleText": "å½•éŸ³","navigationStyle": "custom" }
  }
</route>
